import streamlit as st
import google.generativeai as genai
from PIL import Image
import pandas as pd
from datetime import datetime
import torch
import torch.nn as nn
from torchvision import models
import numpy as np
import cv2

# --- 1. 专转 API 住住转 ---
#  砖驻转 转拽
genai.configure(api_key="AIzaSyDJdiYe4VmudGKFQzoCI_MmngD26D4wm1Q")

ALLOWED_PASSWORDS = [
    "dvir2012", "Teacher2012", "Sunset2012", "专2012", "Dvir_2012!",
    "2012EduCheck", "D2012V", "D@2012", "Dvir2012Pro", "Gold2012"
]

# --- 2.  FCN32s ( 转  ) ---
class FCN32s(nn.Module):
    def __init__(self, n_class=2):
        super(FCN32s, self).__init__()
        # 砖转砖  VGG16 住住  砖拽转 转  注 拽专住转 专 砖专转
        vgg = models.vgg16(weights=None)
        self.features = vgg.features
        self.classifier = nn.Sequential(
            nn.Conv2d(512, 4096, 7),
            nn.ReLU(inplace=True),
            nn.Dropout2d(),
            nn.Conv2d(4096, 4096, 1),
            nn.ReLU(inplace=True),
            nn.Dropout2d(),
            nn.Conv2d(4096, n_class, 1),
        )
        self.upscore = nn.ConvTranspose2d(n_class, n_class, 64, stride=32, bias=False)

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        x = self.upscore(x)
        return x

def prepare_image(img_pil):
    """ 转 转  -FCN"""
    img = np.array(img_pil.convert('RGB'))
    img = cv2.resize(img, (512, 512))
    img = img.astype(np.float32) / 255.0
    img = np.transpose(img, (2, 0, 1))
    return torch.from_numpy(img).unsqueeze(0)

# --- 3. 注转 砖 (Caching) ---
@st.cache_resource
def load_hw_model():
    model = FCN32s(n_class=2)
    model.eval()
    return model

hw_model = load_hw_model()

# --- 4. 注爪 砖拽 砖转砖 (UI) ---
st.set_page_config(page_title="EduCheck AI Pro", layout="wide")
st.markdown("""
<style>
    .stApp { background-color: #0f172a; color: white; direction: rtl; text-align: right; }
    .card { background: rgba(30, 41, 59, 0.7); border: 1px solid #38bdf8; border-radius: 15px; padding: 25px; margin-top: 10px; }
    .stButton>button { background: linear-gradient(90deg, #38bdf8, #1d4ed8); color: white; font-weight: bold; width: 100%; border-radius: 10px; }
    h1, h2, h3 { color: #38bdf8 !important; }
</style>
""", unsafe_allow_html=True)

#  爪 砖 (Session State)
if 'logged_in' not in st.session_state: st.session_state.logged_in = False
if 'reports' not in st.session_state: st.session_state.reports = []

# --- 5. 住 住 ---
if not st.session_state.logged_in:
    _, col, _ = st.columns([1, 1.2, 1])
    with col:
        st.markdown("<div class='card' style='margin-top:20vh; text-align:center;'>", unsafe_allow_html=True)
        st.header("住转 专 专砖")
        pwd = st.text_input(" 拽 砖:", type="password")
        if st.button("转专转"):
            if pwd in ALLOWED_PASSWORDS:
                st.session_state.logged_in = True
                st.rerun()
            else:
                st.error("拽 砖 砖")
        st.markdown("</div>", unsafe_allow_html=True)

# --- 6. 砖拽 专 ---
else:
    st.title("EduCheck AI Pro -   专 ")
    
    with st.sidebar:
        st.success("专 注专转")
        if st.button("转转拽 "):
            st.session_state.logged_in = False
            st.rerun()

    tab1, tab2 = st.tabs([" 拽转 ", " 专 转"])

    with tab1:
        col_r, col_l = st.columns([1, 1])
        
        with col_r:
            st.markdown("<div class='card'>", unsafe_allow_html=True)
            name = st.text_input("砖 转:")
            subject = st.selectbox("拽爪注:", ["转专", "专", "注", "注专转", "专"])
            up_img = st.file_uploader("注 爪  (JPG/PNG):", type=['jpg', 'jpeg', 'png'])
            cam_img = st.camera_input(" 爪 注砖")
            st.markdown("</div>", unsafe_allow_html=True)

        with col_l:
            st.subheader("转爪转 转 -AI")
            active_img = cam_img if cam_img else up_img
            
            if st.button(" 专抓 拽 驻转"):
                if active_img and name:
                    with st.spinner("转 转  砖 爪..."):
                        try:
                            # 砖 : 转 转 专爪转  -FCN
                            img_pil = Image.open(active_img)
                            processed_tensor = prepare_image(img_pil)
                            with torch.no_grad():
                                _ = hw_model(processed_tensor)
                            
                            # 砖 : 转 转 注 Gemini
                            model = genai.GenerativeModel('gemini-1.5-flash')
                            prompt = f"转 转  砖 {name} 拽爪注 {subject}. 拽住  转  注专. 驻注 转, 转 爪 住驻专 砖 砖 ."
                            response = model.generate_content([prompt, img_pil])
                            
                            # 砖专 专
                            st.session_state.reports.append({
                                "砖": name, "拽爪注": subject, 
                                "": response.text, "": datetime.now().strftime("%d/%m %H:%M")
                            })
                            
                            st.markdown(f"<div class='card'>{response.text}</div>", unsafe_allow_html=True)
                        except Exception as e:
                            st.error(f"专注 砖 转: {e}")
                else:
                    st.warning("  砖 转 注 转 砖 .")

    with tab2:
        if not st.session_state.reports:
            st.info("注  转 专.")
        else:
            for r in reversed(st.session_state.reports):
                with st.expander(f" {r['砖']} - {r['拽爪注']} ({r['']})"):
                    st.markdown(r[''])
